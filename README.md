# Iris Dataset â€“ Data Drift, Fairness, and Explainability Analysis

## ðŸ“Œ Overview

This project demonstrates a complete workflow for:

* Detecting **data drift** between reference and current datasets.
* Evaluating **model fairness** across a sensitive attribute.
* Providing **model explainability** using SHAP.

It uses the **Iris dataset** with an added synthetic `location` feature to simulate sensitive attributes and an artificial data drift scenario.

---

## ðŸš€ Features

1. **Data Drift Detection** â€“ Using [Evidently AI](https://github.com/evidentlyai/evidently) to compare reference vs. current datasets.
2. **Fairness Evaluation** â€“ Using [Fairlearn](https://fairlearn.org/) to check model performance across different sensitive groups.
3. **Model Training** â€“ Decision Tree classifier trained on clean reference data.
4. **Model Explainability** â€“ Using [SHAP](https://shap.readthedocs.io/en/latest/) to understand feature importance for predictions.

---

## ðŸ“‚ Project Structure

```
train.ipynb       # Main notebook
iris.csv          # Dataset (optional, auto-generated if not found)
```

---

## ðŸ›  Installation

```bash
# Clone this repository
git clone <repo-url>
cd <repo-folder>

# Install dependencies
pip install pandas numpy scikit-learn evidently fairlearn shap
```

---

## ðŸ“Š Workflow

1. **Data Preparation**

   * Load Iris dataset from `iris.csv` or sklearn.
   * Add a synthetic `location` column (0 or 1).
   * Create a *current* dataset with artificial noise to simulate drift.

2. **Data Drift Analysis**

   * Compare reference (clean) dataset with current (noisy) dataset.
   * Generate drift and data summary reports using Evidently.

3. **Fairness Analysis**

   * Train a Decision Tree classifier.
   * Evaluate accuracy overall and per sensitive group (`location`).

4. **Model Explainability**

   * Use SHAP to explain predictions for the `virginica` class.
   * Visualize feature contributions with force plots.

---

## ðŸ“ˆ Example Outputs

* **Drift Report** â€“ Identifies numerical & categorical feature drift.
* **Fairness Report** â€“ Shows performance disparities across `location`.
* **SHAP Plots** â€“ Highlights feature importance for predictions.

